{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# I. Import Libraries\nHere we will be focusing on Torchvision since it has Transfer Learning feature and quiet comfortable to use.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport copy\nimport time\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom skimage import io\nfrom sklearn.preprocessing import LabelEncoder\nfrom mpl_toolkits.axes_grid1 import ImageGrid","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:17.477423Z","iopub.execute_input":"2021-10-03T06:13:17.478170Z","iopub.status.idle":"2021-10-03T06:13:23.540565Z","shell.execute_reply.started":"2021-10-03T06:13:17.478083Z","shell.execute_reply":"2021-10-03T06:13:23.539424Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# II. Import Necessary Data For Training, Validation & Testing","metadata":{}},{"cell_type":"markdown","source":"Here, we have 9 kinds of fish that we will try to classify. These are :\n1. Hourse Mackerel\n2. Black Sea Sprat\n3. Sea Bass\n4. Red Mullet\n5. Trout\n6. Striped Red Mullet\n7. Shrimp\n8. Gilt-Head Bream\n9. Red Sea Bream","metadata":{}},{"cell_type":"code","source":"os.listdir('../input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset')","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:23.542565Z","iopub.execute_input":"2021-10-03T06:13:23.542908Z","iopub.status.idle":"2021-10-03T06:13:23.566425Z","shell.execute_reply.started":"2021-10-03T06:13:23.542867Z","shell.execute_reply":"2021-10-03T06:13:23.565351Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_class = ['Hourse Mackerel', 'Black Sea Sprat', 'Sea Bass', 'Red Mullet', 'Trout', 'Striped Red Mullet',\n             'Shrimp', 'Gilt-Head Bream', 'Red Sea Bream']\n\nlist_dir = []\nlist_class = []\nmain_dir = '../input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n\nfor i in img_class:\n    dirs = main_dir + '/' + i + '/' + i\n    the_files = []\n    for _, __, f in os.walk(dirs):\n        the_files.append(f)\n        for ff in the_files[0]:\n            add = i + '/' + i + '/' + ff\n            list_dir.append(add)\n            list_class.append(i)\n            \ndf_img = pd.DataFrame({'dir':list_dir, 'class':list_class})","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:23.569717Z","iopub.execute_input":"2021-10-03T06:13:23.569980Z","iopub.status.idle":"2021-10-03T06:13:25.405778Z","shell.execute_reply.started":"2021-10-03T06:13:23.569938Z","shell.execute_reply":"2021-10-03T06:13:25.404608Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class fish_dataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.annotations = df\n        self.root_dir = root_dir\n        self.transform = transform\n    def __len__(self):\n        return len(self.annotations)\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n        image = io.imread(img_path)\n        y_label = self.annotations.iloc[index, 1]\n        if self.transform != None:\n            image = self.transform(image)\n        return (image, y_label)\n    \nimg_transformer = transforms.ToTensor()\n    \nscaled_fish_dataset = fish_dataset(df_img, main_dir, img_transformer)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:25.410675Z","iopub.execute_input":"2021-10-03T06:13:25.410928Z","iopub.status.idle":"2021-10-03T06:13:25.422465Z","shell.execute_reply.started":"2021-10-03T06:13:25.410884Z","shell.execute_reply":"2021-10-03T06:13:25.421418Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_set, valid_set = random_split(scaled_fish_dataset, [5000, 4000])\nvalid_set, test_set = random_split(valid_set, [2000, 2000])\n\ntrain_dataloader = DataLoader(train_set, shuffle=True, batch_size=10, num_workers=4)\nvalid_dataloader = DataLoader(valid_set, shuffle=True, batch_size=10, num_workers=4)\ntest_dataloader = DataLoader(test_set, shuffle=True, batch_size=10, num_workers=4)\n\ndataloader = {'train':train_dataloader, 'valid':valid_dataloader}\ndataset_size = {'train': len(train_set), 'valid': len(valid_set)}","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:25.426812Z","iopub.execute_input":"2021-10-03T06:13:25.427070Z","iopub.status.idle":"2021-10-03T06:13:25.454676Z","shell.execute_reply.started":"2021-10-03T06:13:25.427043Z","shell.execute_reply":"2021-10-03T06:13:25.453589Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# III. Showing Some Examples of the Data","metadata":{}},{"cell_type":"code","source":"def transform_to_numpy(inp):\n    inp = inp.numpy()\n    i, x, y, z = inp.shape\n    inp_new = inp[0].transpose((1, 2, 0)).reshape(1, y, z, x)\n    for inp_add in inp[1:]:\n        inp_add = inp_add.transpose((1, 2, 0)).reshape(1, y, z, x)\n        inp_new = np.vstack([inp_new, inp_add])\n    return inp_new\n\ninputs, labels = next(iter(test_dataloader))\ninputs = transform_to_numpy(inputs)    \n\nfig = plt.figure(figsize=(14, 7))\ngrid = ImageGrid(fig, 111, nrows_ncols=(2, 5), axes_pad=0.1)\n\nfor pic, g in zip(inputs, grid):\n    g.imshow(pic)\n    \nprint('{}\\t{}\\t{}\\t{}\\t{}'.format(labels[0], labels[1], labels[2], labels[3], labels[4]))\nprint('{}\\t{}\\t{}\\t{}\\t{}'.format(labels[5], labels[6], labels[7], labels[8], labels[9]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:25.456187Z","iopub.execute_input":"2021-10-03T06:13:25.456501Z","iopub.status.idle":"2021-10-03T06:13:28.853344Z","shell.execute_reply.started":"2021-10-03T06:13:25.456449Z","shell.execute_reply":"2021-10-03T06:13:28.852367Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# IV. Training the Model","metadata":{}},{"cell_type":"markdown","source":"Because we will be using transfer learning here, we only need to train the last layer. We will use this pre-trained model as the feature extractor, which has a function to extract the feature from each picture that it process. The last layer is our classifier which we build specific for this particular problem.","metadata":{}},{"cell_type":"code","source":"def develop_model(model, encoder, criterion, optimizer, scheduler, num_epochs):\n    since = time.time()\n    best_acc = 0.0\n    best_model_wts = copy.deepcopy(model.state_dict())\n    \n    for epoch in range(num_epochs):\n        print('Epoch : {}/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n        \n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()\n            elif phase == 'valid':\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            for inputs, labels in dataloader[phase]:\n                inputs = inputs.to(device)\n                labels = torch.Tensor(encoder.transform(labels)).to(device)\n                labels = labels.long()\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, predictions = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n                    \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(predictions == labels.data)\n            if phase == 'train':\n                scheduler.step()\n                \n            epoch_loss = running_loss / dataset_size[phase]\n            epoch_acc = running_corrects.double() / dataset_size[phase]\n            \n            if (phase == 'valid') and (epoch_acc > best_acc):\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n            print('{} Loss : {:.3f} Accuracy {:.3f}'.format(phase, epoch_loss, epoch_acc))\n        print()\n        \n    time_elapsed = time.time() - since\n    \n    print('The elapsed time is {} minutes {:.1f} seconds'.format(int(time_elapsed // 60), time_elapsed % 60))\n    print('The best accuracy is {:.2f}%'.format(best_acc * 100))\n    \n    model.load_state_dict(best_model_wts)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:28.854798Z","iopub.execute_input":"2021-10-03T06:13:28.855117Z","iopub.status.idle":"2021-10-03T06:13:28.875148Z","shell.execute_reply.started":"2021-10-03T06:13:28.855075Z","shell.execute_reply":"2021-10-03T06:13:28.873867Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"le_process = LabelEncoder().fit(img_class)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel = models.resnet18(pretrained=True)\nfor parameter in model.parameters():\n    parameter.requires_grad = False\nmodel_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(model_ftrs, len(img_class))\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.fc.parameters(), lr=5e-3, momentum=0.9)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nmodel = develop_model(model, le_process, criterion, optimizer, scheduler, num_epochs=8)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:13:28.877003Z","iopub.execute_input":"2021-10-03T06:13:28.877476Z","iopub.status.idle":"2021-10-03T06:26:59.407307Z","shell.execute_reply.started":"2021-10-03T06:13:28.877433Z","shell.execute_reply":"2021-10-03T06:26:59.404846Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# V. Testing","metadata":{}},{"cell_type":"markdown","source":"The last step is Testing. Let's see how it goes.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom tqdm.auto import tqdm\n\npreds = []\ntargs = []\n\nprogress_bar = tqdm(range(len(test_dataloader)))\n\nfor inputs, labels in test_dataloader:\n    inputs = inputs.to(device)\n    labels = le_process.transform(labels)\n    with torch.no_grad():\n        outputs = model(inputs)\n    _, predictions = torch.max(outputs, 1)\n    predictions = predictions.cpu().numpy()\n    for pred, targ in zip(predictions, labels):\n        preds.append(pred)\n        targs.append(targ)\n    progress_bar.update(1)\n        \ntest_score = accuracy_score(preds, targs)\nprint('The accuracy of the test is {:.2f}%'.format(test_score * 100))","metadata":{"execution":{"iopub.status.busy":"2021-10-03T06:26:59.409305Z","iopub.execute_input":"2021-10-03T06:26:59.409795Z","iopub.status.idle":"2021-10-03T06:27:31.160723Z","shell.execute_reply.started":"2021-10-03T06:26:59.409748Z","shell.execute_reply":"2021-10-03T06:27:31.159553Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"The accuracy of the test is 99.80%. Well it's high, but it depends on you to decide is it a good thing or not. It can be an indication of overfitting as we all know that the data that we have here doesn't have much varieties. ","metadata":{}}]}